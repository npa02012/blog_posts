{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried creating transformer/MHA attention models using Pytorch for Kaggle's [riiid](https://www.kaggle.com/c/riiid-test-answer-prediction) and [indoor-location-navigation](https://www.kaggle.com/c/indoor-location-navigation) competitions. Here are the links to the notebooks:\n",
    "\n",
    "* https://www.kaggle.com/npa02012/location-floor-mha\n",
    "* https://www.kaggle.com/npa02012/location-xy-mha\n",
    "* https://www.kaggle.com/npa02012/riiid-model-mha\n",
    "* https://www.kaggle.com/npa02012/riiid-model-transformer\n",
    "\n",
    "In case Kaggle purges these notebooks, I'm copying the content below:  \n",
    "\n",
    "#### location-floor-mha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/location-competition/indoor-location-competition-20\n",
    "# https://www.kaggle.com/c/indoor-location-navigation/data\n",
    "# https://www.kaggle.com/titericz/eda-loading-data-and-visualizing-paths\n",
    "# https://www.kaggle.com/npa02012/time-to-complete-trace-eda\n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "# www.reddit.com/r/MachineLearning/comments/4dzxs3/best_way_to_deal_with_time_series_data\n",
    "# https://arxiv.org/pdf/1907.03907.pdf\n",
    "# https://github.com/YuliaRubanova/latent_ode\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "settings = {\n",
    "    'beacon_seq_len' : 50\n",
    "    ,'beacon_embed_dim' : 256\n",
    "    ,'device' : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ,'floor_mapping' : {'B1' : -1, 'B2' : -2, 'B3' : -3\n",
    "                         ,'F1' : 0, 'F2' : 1, 'F3' : 2, 'F4' : 3, 'F5' : 4\n",
    "                         ,'F6' : 5, 'F7' : 6 , 'F8' : 7, 'F9' : 8, 'F10' : 9\n",
    "                         ,'1F' : 0, '2F' : 1, '3F' : 2, '4F' : 3, '5F' : 4\n",
    "                         ,'6F' : 5, '7F' : 6, '8F' : 7, '9F' : 8\n",
    "                        }\n",
    "    ,'n_floor' : 13\n",
    "    ,'max_beacon_distance' : 200\n",
    "    ,'path_train' : '../input/indoor-location-navigation/train/*/*/*'\n",
    "    ,'path_test' : '../input/indoor-location-navigation/test/*'\n",
    "    ,'path_sample' : '../input/indoor-location-navigation/sample_submission.csv'\n",
    "}\n",
    "\n",
    "## ---\n",
    "\n",
    "with open('../input/location-data/beacon_train.pkl', 'rb') as handle:\n",
    "    train = pickle.load(handle)\n",
    "    \n",
    "# Delete rows with 'unusual' floors\n",
    "i = train['df'][~train['df']['floor'].isin(settings['floor_mapping'].keys())].index\n",
    "train['df'].drop(i, inplace=True)\n",
    "\n",
    "# Only keep initial rows of a trace\n",
    "train['df'] = train['df'].groupby('trace_id')\\\n",
    "                .head(settings['beacon_seq_len']).reset_index(drop=True)\n",
    "\n",
    "# Convert distance column to int\n",
    "tmp = settings['max_beacon_distance']\n",
    "train['df']['distance'] = np.where(train['df'][\"distance\"]>tmp, tmp, train['df'][\"distance\"])\n",
    "train['df']['distance'] = np.where(train['df'][\"distance\"]<0, 0, train['df'][\"distance\"])\n",
    "train['df']['distance'] = train['df']['distance'].astype(int) + 1\n",
    "\n",
    "# Map columns\n",
    "train['df']['site_id'] = train['df']['site_id'].astype('category').cat.codes + 1\n",
    "train['df']['UUID'] = train['df']['UUID'].astype('category').cat.codes + 1\n",
    "train['df']['MinorID'] = train['df']['MinorID'].astype('category').cat.codes + 1\n",
    "train['df']['MajorID'] = train['df']['MajorID'].astype('category').cat.codes + 1\n",
    "train['df']['MAC_Address'] = train['df']['MAC_Address'].astype('category').cat.codes + 1\n",
    "train['df'].replace({'floor' : settings['floor_mapping']}, inplace=True)\n",
    "\n",
    "# Record settings\n",
    "settings['n_uuids'] = train['df']['UUID'].max() + 1\n",
    "settings['n_minor_ids'] = train['df']['MinorID'].max() + 1\n",
    "settings['n_major_ids'] = train['df']['MajorID'].max() + 1\n",
    "settings['n_macs'] = train['df']['MAC_Address'].max() + 1\n",
    "settings['n_sites'] = train['df']['site_id'].max() + 1\n",
    "\n",
    "# Convert to dictionary\n",
    "train['df'] = {k: table for k, table in train['df'].groupby(\"trace_id\")} # slower, but easier\n",
    "\n",
    "train['df']['5d09b22fcfb49b00085466a0']\n",
    "\n",
    "# Make validation set\n",
    "np.random.seed(1)\n",
    "val_idx = np.random.choice(list(train['df'].keys())\n",
    "                           ,int(.2 * len(train['df'].keys())), replace=False)\n",
    "valid = {'df' : {}}\n",
    "for i in val_idx:\n",
    "    valid['df'][i] = train['df'][i].copy()\n",
    "    del train['df'][i]\n",
    "    \n",
    "class beacon_dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, group, settings):\n",
    "        super(beacon_dataset, self).__init__()\n",
    "        self.beacon_seq_len = settings['beacon_seq_len']\n",
    "        self.n_floor = settings['n_floor']\n",
    "        self.group = group\n",
    "        self.trace_ids = list(group.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.trace_ids))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the relevant user row\n",
    "        sample = self.group[self.trace_ids[index]]\n",
    "        \n",
    "        # Get contents as np.int64s\n",
    "        uuids = sample['UUID'].values\n",
    "        distances = sample['distance'].values\n",
    "        minor_ids = sample['MinorID'].values\n",
    "        major_ids = sample['MajorID'].values\n",
    "        macs = sample['MAC_Address'].values\n",
    "        sites = sample['site_id'].values\n",
    "        \n",
    "        # Pad if needed\n",
    "        n_pad = self.beacon_seq_len - len(uuids)\n",
    "        if n_pad > 0:\n",
    "            uuids = np.concatenate((uuids, np.full(n_pad, 0).astype(np.int64)))\n",
    "            distances = np.concatenate((distances, np.full(n_pad, 0).astype(np.int64)))\n",
    "            minor_ids = np.concatenate((minor_ids, np.full(n_pad, 0).astype(np.int64))) \n",
    "            major_ids = np.concatenate((major_ids, np.full(n_pad, 0).astype(np.int64)))\n",
    "            macs = np.concatenate((macs, np.full(n_pad, 0).astype(np.int64)))\n",
    "            sites = np.concatenate((sites, np.full(n_pad, 0).astype(np.int64)))\n",
    "        else:\n",
    "            uuids = uuids[:self.beacon_seq_len]\n",
    "            distances = distances[:self.beacon_seq_len]\n",
    "            minor_ids = minor_ids[:self.beacon_seq_len]\n",
    "            major_ids = major_ids[:self.beacon_seq_len]\n",
    "            macs = macs[:self.beacon_seq_len]\n",
    "            sites = sites[:self.beacon_seq_len]\n",
    "\n",
    "        \n",
    "        # Return\n",
    "        return({\n",
    "            'floor' : sample.iloc[0]['floor'] + 3#np.array(floor)\n",
    "            ,'uuids' : uuids\n",
    "            ,'distances' : distances\n",
    "            ,'minor_ids' : minor_ids\n",
    "            ,'major_ids' : major_ids\n",
    "            ,'macs' : macs\n",
    "            ,'sites' : sites\n",
    "        })\n",
    "    \n",
    "\n",
    "train_dataset = beacon_dataset(group = train['df']\n",
    "                              ,settings = settings\n",
    "                              )\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset\n",
    "                                                ,batch_size = 128\n",
    "                                                ,drop_last = True\n",
    "                                                ,shuffle = True\n",
    "                                                ,num_workers = 4\n",
    "                                               )\n",
    "\n",
    "valid_dataset = beacon_dataset(group = valid['df']\n",
    "                              ,settings = settings\n",
    "                              )\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset\n",
    "                                                ,batch_size = 10\n",
    "                                                ,num_workers = 4\n",
    "                                               )\n",
    "\n",
    "valid_dataset.__getitem__(1)\n",
    "\n",
    "class floor_model(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(floor_model, self).__init__()\n",
    "        self.embed_dim = settings['beacon_embed_dim']\n",
    "        self.seq_len = settings['beacon_seq_len']\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        self.minor_id_embedding = torch.nn.Embedding(settings['n_minor_ids']\n",
    "                                                    ,self.embed_dim)\n",
    "        self.major_id_embedding = torch.nn.Embedding(settings['n_major_ids']\n",
    "                                                    ,self.embed_dim)\n",
    "        self.uuid_embedding = torch.nn.Embedding(settings['n_uuids']\n",
    "                                                 ,self.embed_dim)\n",
    "        self.mac_embedding = torch.nn.Embedding(settings['n_macs']\n",
    "                                                 ,self.embed_dim)\n",
    "        # Site embedding doesn't make to much sense (same site always)\n",
    "        self.site_embedding = torch.nn.Embedding(settings['n_sites']\n",
    "                                                ,self.embed_dim)\n",
    "        self.distance_embedding = torch.nn.Embedding(settings['max_beacon_distance']+2\n",
    "                                                     ,self.embed_dim)\n",
    "        self.pos_embedding = torch.nn.Embedding(self.seq_len, self.embed_dim)\n",
    "        self.multi_att = torch.nn.MultiheadAttention(embed_dim = self.embed_dim\n",
    "                                                     ,num_heads = 4\n",
    "                                                     ,dropout = 0.2)\n",
    "\n",
    "        self.lin_1 = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.lin_2 = torch.nn.Linear(self.embed_dim, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.pred = torch.nn.Linear(self.seq_len, settings['n_floor'])\n",
    "        \n",
    "        self.tmp = True\n",
    "            \n",
    "    def forward(self, batch):        \n",
    "        # Minor id embedding\n",
    "        x = self.minor_id_embedding(batch['minor_ids'].long())\n",
    "        \n",
    "        # MAC Address embedding\n",
    "        x = x + self.mac_embedding(batch['macs'].long())\n",
    "        \n",
    "        # Site embedding\n",
    "        x = x + self.site_embedding(batch['sites'].long())\n",
    "        \n",
    "        # Major Id embedding\n",
    "        x = x + self.major_id_embedding(batch['major_ids'].long())\n",
    "        \n",
    "        # UUID embedding\n",
    "        #x = x + self.uuid_embedding(batch['uuids'].long())\n",
    "        \n",
    "        # Distance embedding\n",
    "        x = x + self.distance_embedding(batch['distances'])\n",
    "        \n",
    "        # Position embedding\n",
    "        pos_id = torch.arange(x.shape[1])[None, :].to(self.device)\n",
    "        x = x + self.pos_embedding(pos_id)\n",
    "        \n",
    "        # Permute\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        \n",
    "        # MultiHead Attention and permute back\n",
    "        attn_output, _ = self.multi_att(x, x, x)\n",
    "        x = x + attn_output\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Feed forward\n",
    "        x = self.lin_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Predict\n",
    "        x = x[:, :, -1]\n",
    "        x = self.pred(x)\n",
    "        \n",
    "        # Return\n",
    "        return(x)\n",
    "        \n",
    "\n",
    "# Setup model, optimizer and criterion\n",
    "model = floor_model(settings)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.002)\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "all_auc = []\n",
    "\n",
    "# Move model and criteriod to device\n",
    "model.to(settings['device'])\n",
    "criterion.to(settings['device'])\n",
    "all_loss = []\n",
    "\n",
    "\n",
    "for _ in range(25):\n",
    "    tbar = tqdm.tqdm(train_dataloader)\n",
    "    for batch in tbar:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(settings['device'])\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch['floor'].long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record metrics\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "print(np.array(all_loss[-200:]).mean())\n",
    "matplotlib.pyplot.plot(all_loss)\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "def get_acc(dataset):\n",
    "    if dataset == 'valid':\n",
    "        dl = valid_dataloader\n",
    "    else:\n",
    "        dl = train_dataloader\n",
    "    # Accuracy mesurments\n",
    "    preds = np.empty(0, dtype=np.int64)\n",
    "    labels = np.empty(0, dtype=np.int64)\n",
    "\n",
    "    model.eval()\n",
    "    for batch in dl:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(settings['device'])\n",
    "\n",
    "        # Get predictions\n",
    "        pred = model(batch)\n",
    "        p = pred.detach().to('cpu').numpy()\n",
    "        p = np.argmax(p, axis = 1)\n",
    "        preds = np.concatenate((preds, p))\n",
    "\n",
    "        # Label\n",
    "        l = batch['floor'].detach().to('cpu').numpy()\n",
    "        labels = np.concatenate((labels, l))\n",
    "    model.train()\n",
    "    print(dataset)\n",
    "    print(np.sum(preds == labels)/preds.shape[0])\n",
    "    print((15 * abs(preds - labels)).mean())\n",
    "    \n",
    "    \n",
    "# Get accuracy\n",
    "get_acc('valid')\n",
    "get_acc('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### location-xy-mha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Continuous embedding:\n",
    "#  https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/210171\n",
    "#  https://github.com/dkletran/riiid-challenge-4th-place/blob/main/modeling_training/modeling.py\n",
    "#  https://arxiv.org/pdf/2010.12042.pdf\n",
    "#\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "settings = {\n",
    "    'beacon_seq_len' : 50\n",
    "    ,'beacon_embed_dim' : 256\n",
    "    ,'device' : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ,'floor_mapping' : {'B1' : -1, 'B2' : -2, 'B3' : -3\n",
    "                         ,'F1' : 0, 'F2' : 1, 'F3' : 2, 'F4' : 3, 'F5' : 4\n",
    "                         ,'F6' : 5, 'F7' : 6 , 'F8' : 7, 'F9' : 8, 'F10' : 9\n",
    "                         ,'1F' : 0, '2F' : 1, '3F' : 2, '4F' : 3, '5F' : 4\n",
    "                         ,'6F' : 5, '7F' : 6, '8F' : 7, '9F' : 8\n",
    "                        }\n",
    "    ,'n_floor' : 13\n",
    "    ,'max_beacon_distance' : 200\n",
    "    ,'path_train' : '../input/indoor-location-navigation/train/*/*/*'\n",
    "    ,'path_test' : '../input/indoor-location-navigation/test/*'\n",
    "    ,'path_sample' : '../input/indoor-location-navigation/sample_submission.csv'\n",
    "}\n",
    "\n",
    "with open('../input/location-data/wp_train.pkl', 'rb') as handle:\n",
    "    train = pickle.load(handle)\n",
    "    \n",
    "with open('../input/location-data/beacon_train.pkl', 'rb') as handle:\n",
    "    tmp = pickle.load(handle)\n",
    "    \n",
    "# Handle this in other script eventually\n",
    "train['wp'] = train.pop('df')\n",
    "train['beacon'] = tmp.pop('df')\n",
    "train['wp'].x = train['wp'].x.astype('float')\n",
    "train['wp'].y = train['wp'].y.astype('float')\n",
    "\n",
    "\n",
    "with open('../input/location-data/wp_train.pkl', 'rb') as handle:\n",
    "    train = pickle.load(handle)\n",
    "    \n",
    "with open('../input/location-data/beacon_train.pkl', 'rb') as handle:\n",
    "    tmp = pickle.load(handle)\n",
    "    \n",
    "# Handle this in other script eventually\n",
    "train['wp'] = train.pop('df')\n",
    "train['beacon'] = tmp.pop('df')\n",
    "train['wp'].x = train['wp'].x.astype('float')\n",
    "train['wp'].y = train['wp'].y.astype('float')\n",
    "\n",
    "#\n",
    "# Delete trace_ids not in beacon\n",
    "# ***** Delete this eventually\n",
    "#\n",
    "train['wp'] = train['wp'].loc[train['wp'].trace_id.isin(train['beacon'].trace_id)]\n",
    "\n",
    "# Record settings for embedding\n",
    "settings['n_uuids'] = train['beacon']['UUID'].nunique() + 1\n",
    "settings['n_minor_ids'] = train['beacon']['MinorID'].nunique() + 1\n",
    "settings['n_major_ids'] = train['beacon']['MajorID'].nunique() + 1\n",
    "settings['n_macs'] = train['beacon']['MAC_Address'].nunique() + 1\n",
    "settings['n_sites'] = train['beacon']['site_id'].nunique() + 1\n",
    "\n",
    "#\n",
    "# Make validation set\n",
    "#\n",
    "\n",
    "# Get trace_ids to be in validation set\n",
    "np.random.seed(1)\n",
    "tmp = train['wp'].trace_id.unique()\n",
    "valid_ids = np.random.choice(tmp, int(.2 * tmp.shape[0]), replace=False)\n",
    "\n",
    "# Make validation set\n",
    "valid = {}\n",
    "valid['beacon'] = train['beacon'].loc[train['beacon'].trace_id.isin(valid_ids)]\n",
    "valid['wp'] = train['wp'].loc[train['wp'].trace_id.isin(valid_ids)]\n",
    "\n",
    "# Delete validation set from train\n",
    "train['beacon'] = train['beacon'].loc[~train['beacon'].trace_id.isin(valid_ids)]\n",
    "train['wp'] = train['wp'].loc[~train['wp'].trace_id.isin(valid_ids)]\n",
    "\n",
    "def clean_data(data, settings):\n",
    "    \n",
    "    # Delete rows with 'non-testing' floors\n",
    "    i = data['wp'][~data['wp']['floor'].isin(settings['floor_mapping'].keys())].index\n",
    "    data['wp'].drop(i, inplace=True)\n",
    "    i = data['beacon'][~data['beacon']['floor']\\\n",
    "                        .isin(settings['floor_mapping'].keys())].index\n",
    "    data['beacon'].drop(i, inplace=True)\n",
    "    \n",
    "    # Reset indices\n",
    "    data['wp'].reset_index(drop=True, inplace=True)\n",
    "    data['beacon'].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Only keep initial rows of a trace\n",
    "    data['beacon'] = data['beacon'].groupby('trace_id')\\\n",
    "                    .head(settings['beacon_seq_len']).reset_index(drop=True)\n",
    "\n",
    "    # Convert distance column to int\n",
    "    tmp = settings['max_beacon_distance']\n",
    "    data['beacon']['distance'] = np.where(data['beacon'][\"distance\"] > tmp\n",
    "                                       ,tmp, data['beacon'][\"distance\"])\n",
    "    data['beacon']['distance'] = np.where(data['beacon'][\"distance\"] < 0\n",
    "                                       ,0, data['beacon'][\"distance\"])\n",
    "    data['beacon']['distance'] = data['beacon']['distance'].astype(int) + 1\n",
    "\n",
    "    # Map columns\n",
    "    data['beacon']['site_id'] = data['beacon']['site_id'].astype('category').cat.codes + 1\n",
    "    data['beacon']['UUID'] = data['beacon']['UUID'].astype('category').cat.codes + 1\n",
    "    data['beacon']['MinorID'] = data['beacon']['MinorID'].astype('category').cat.codes + 1\n",
    "    data['beacon']['MajorID'] = data['beacon']['MajorID'].astype('category').cat.codes + 1\n",
    "    data['beacon']['MAC_Address'] = data['beacon']['MAC_Address'].astype('category').cat.codes + 1\n",
    "    data['beacon'].replace({'floor' : settings['floor_mapping']}, inplace=True)\n",
    "\n",
    "    # Convert to dictionary\n",
    "    data['beacon'] = {k: table for k, table in data['beacon'].groupby(\"trace_id\")} # Can optimize\n",
    "    data['wp'] = data['wp'].to_dict(orient='index')\n",
    "    \n",
    "    # Return\n",
    "    return(data)\n",
    "\n",
    "train = clean_data(train, settings)\n",
    "valid = clean_data(valid, settings)\n",
    "\n",
    "print(train['wp'][0])\n",
    "valid['beacon'][list(valid['beacon'].keys())[0]].head()\n",
    "\n",
    "class location_dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, settings):\n",
    "        super(location_dataset, self).__init__()\n",
    "        self.beacon_seq_len = settings['beacon_seq_len']\n",
    "        self.n_floor = settings['n_floor']\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.data['wp'].keys()))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the relevant user data\n",
    "        wp = self.data['wp'][index]\n",
    "        beacon = self.data['beacon'][wp['trace_id']]\n",
    "        \n",
    "        # Get contents as np.int64s\n",
    "        uuids = beacon['UUID'].values\n",
    "        distances = beacon['distance'].values\n",
    "        minor_ids = beacon['MinorID'].values\n",
    "        major_ids = beacon['MajorID'].values\n",
    "        macs = beacon['MAC_Address'].values\n",
    "        sites = beacon['site_id'].values\n",
    "        \n",
    "        # Pad if needed\n",
    "        n_pad = self.beacon_seq_len - len(uuids)\n",
    "        if n_pad > 0:\n",
    "            uuids = np.concatenate((uuids, np.full(n_pad, 0).astype(np.int64)))\n",
    "            distances = np.concatenate((distances, np.full(n_pad, 0).astype(np.int64)))\n",
    "            minor_ids = np.concatenate((minor_ids, np.full(n_pad, 0).astype(np.int64))) \n",
    "            major_ids = np.concatenate((major_ids, np.full(n_pad, 0).astype(np.int64)))\n",
    "            macs = np.concatenate((macs, np.full(n_pad, 0).astype(np.int64)))\n",
    "            sites = np.concatenate((sites, np.full(n_pad, 0).astype(np.int64)))\n",
    "        else:\n",
    "            uuids = uuids[:self.beacon_seq_len]\n",
    "            distances = distances[:self.beacon_seq_len]\n",
    "            minor_ids = minor_ids[:self.beacon_seq_len]\n",
    "            major_ids = major_ids[:self.beacon_seq_len]\n",
    "            macs = macs[:self.beacon_seq_len]\n",
    "            sites = sites[:self.beacon_seq_len]\n",
    "            \n",
    "        # Location of waypoint timestamp\n",
    "        #tmp = train['beacon']['5d09b23ccfb49b00085466a6'].timestamp\n",
    "        #print(tmp)\n",
    "        #tmp2 = tmp.loc[tmp > 15609164469999].index.min()\n",
    "\n",
    "        \n",
    "        # Return\n",
    "        return({\n",
    "            'x' : wp['x']\n",
    "            ,'y' : wp['y']\n",
    "            ,'uuids' : uuids\n",
    "            ,'distances' : distances\n",
    "            ,'minor_ids' : minor_ids\n",
    "            ,'major_ids' : major_ids\n",
    "            ,'macs' : macs\n",
    "            ,'sites' : sites\n",
    "        })\n",
    "    \n",
    "\n",
    "train_dataset = location_dataset(data = train\n",
    "                              ,settings = settings\n",
    "                              )\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset\n",
    "                                                ,batch_size = 256\n",
    "                                                ,drop_last = True\n",
    "                                                ,shuffle = True\n",
    "                                                ,num_workers = 4\n",
    "                                               )\n",
    "\n",
    "valid_dataset = location_dataset(data = valid\n",
    "                              ,settings = settings\n",
    "                              )\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset\n",
    "                                                ,batch_size = 1000\n",
    "                                                ,num_workers = 4\n",
    "                                               )\n",
    "valid_dataset.__getitem__(1)\n",
    "\n",
    "class xy_model(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(xy_model, self).__init__()\n",
    "        self.embed_dim = settings['beacon_embed_dim']\n",
    "        self.seq_len = settings['beacon_seq_len']\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        self.minor_id_embedding = torch.nn.Embedding(settings['n_minor_ids']\n",
    "                                                    ,self.embed_dim)\n",
    "        self.major_id_embedding = torch.nn.Embedding(settings['n_major_ids']\n",
    "                                                    ,self.embed_dim)\n",
    "        self.uuid_embedding = torch.nn.Embedding(settings['n_uuids']\n",
    "                                                 ,self.embed_dim)\n",
    "        self.mac_embedding = torch.nn.Embedding(settings['n_macs']\n",
    "                                                 ,self.embed_dim)\n",
    "        # Site embedding doesn't make to much sense (same site always)\n",
    "        self.site_embedding = torch.nn.Embedding(settings['n_sites']\n",
    "                                                ,self.embed_dim)\n",
    "        self.distance_embedding = torch.nn.Embedding(settings['max_beacon_distance']+2\n",
    "                                                     ,self.embed_dim)\n",
    "        self.pos_embedding = torch.nn.Embedding(self.seq_len, self.embed_dim)\n",
    "        self.multi_att = torch.nn.MultiheadAttention(embed_dim = self.embed_dim\n",
    "                                                     ,num_heads = 4\n",
    "                                                     ,dropout = 0.2)\n",
    "\n",
    "        self.lin_1 = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.lin_2 = torch.nn.Linear(self.embed_dim, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.pred = torch.nn.Linear(self.seq_len, 2)\n",
    "        \n",
    "            \n",
    "    def forward(self, batch):        \n",
    "        # Minor id embedding\n",
    "        x = self.minor_id_embedding(batch['minor_ids'].long())\n",
    "        \n",
    "        # MAC Address embedding\n",
    "        x = x + self.mac_embedding(batch['macs'].long())\n",
    "        \n",
    "        # Site embedding\n",
    "        x = x + self.site_embedding(batch['sites'].long())\n",
    "        \n",
    "        # Major Id embedding\n",
    "        x = x + self.major_id_embedding(batch['major_ids'].long())\n",
    "        \n",
    "        # UUID embedding\n",
    "        #x = x + self.uuid_embedding(batch['uuids'].long())\n",
    "        \n",
    "        # Distance embedding\n",
    "        x = x + self.distance_embedding(batch['distances'])\n",
    "        \n",
    "        # Position embedding\n",
    "        pos_id = torch.arange(x.shape[1])[None, :].to(self.device)\n",
    "        x = x + self.pos_embedding(pos_id)\n",
    "        \n",
    "        # Permute\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        \n",
    "        # MultiHead Attention and permute back\n",
    "        attn_output, _ = self.multi_att(x, x, x)\n",
    "        x = x + attn_output\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Feed forward\n",
    "        x = self.lin_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Predict\n",
    "        x = x[:, :, -1]\n",
    "        x = self.pred(x)\n",
    "        \n",
    "        # Return\n",
    "        return(x)\n",
    "        \n",
    "\n",
    "# Setup model, optimizer and criterion\n",
    "model = xy_model(settings)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.002)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Move model and criteriod to device\n",
    "model.to(settings['device'])\n",
    "criterion.to(settings['device'])\n",
    "all_loss = []\n",
    "\n",
    "for _ in range(1):\n",
    "    tbar = tqdm.tqdm(train_dataloader)\n",
    "    for batch in tbar:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(settings['device'])\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        targ = torch.cat((batch['x'][:, None], batch['y'][:, None]), 1).float()\n",
    "        loss = criterion(pred, targ)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record metrics\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "print(np.array(all_loss[-200:]).mean())\n",
    "matplotlib.pyplot.plot(all_loss)\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "def score(dataset, settings):\n",
    "    if dataset == 'valid':\n",
    "        dl = valid_dataloader\n",
    "    else:\n",
    "        dl = torch.utils.data.DataLoader(train_dataset\n",
    "                                        ,batch_size = 1000\n",
    "                                        ,num_workers = 4\n",
    "                                       )\n",
    "    # Accuracy mesurments\n",
    "    pred_x = np.empty(0, dtype=np.float)\n",
    "    pred_y = np.empty(0, dtype=np.float)\n",
    "    targ_x = np.empty(0, dtype=np.float)\n",
    "    targ_y = np.empty(0, dtype=np.float)\n",
    "\n",
    "    model.eval()\n",
    "    for batch in dl:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(settings['device'])\n",
    "\n",
    "        # Get predictions\n",
    "        pred = model(batch)\n",
    "        p = pred.detach().to('cpu').numpy()\n",
    "        p_x = p[:, 0]\n",
    "        p_y = p[:, 1]\n",
    "        pred_x = np.concatenate((pred_x, p_x))\n",
    "        pred_y = np.concatenate((pred_y, p_y))\n",
    "\n",
    "        # Target\n",
    "        t_x = batch['x'].detach().to('cpu').numpy()\n",
    "        t_y = batch['x'].detach().to('cpu').numpy()\n",
    "        targ_x = np.concatenate((targ_x, t_x))\n",
    "        targ_y = np.concatenate((targ_y, t_y))\n",
    "        \n",
    "    model.train()\n",
    "    tmp = sum(np.sqrt(np.square(pred_x - targ_x) + np.square(pred_y - targ_y)))/pred_x.shape[0]\n",
    "    print(tmp)\n",
    "    \n",
    "    \n",
    "# Get accuracy\n",
    "score('valid', settings)\n",
    "score('train', settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### riiid-model-mha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/210276\n",
    "# https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
    "\n",
    "# Multihead vs Transformer?\n",
    "# This notebook seems to indicate a Transformer consists of the encoder and decoder blocks:\n",
    "# https://www.kaggle.com/m10515009/saint-is-all-you-need-training-private-0-801\n",
    "\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot\n",
    "\n",
    "import torch\n",
    "\n",
    "settings = {}\n",
    "settings['seq_len'] = 160\n",
    "settings['n_content_id'] = 13525\n",
    "settings['batch_size'] = 100\n",
    "settings['embed_dim'] = 200\n",
    "settings['n_train_rows'] = 5 * 1000000\n",
    "settings['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dtype = {'timestamp':'int64', \n",
    "         'user_id':'int32' ,\n",
    "         'content_id':'int16',\n",
    "         'content_type_id':'int8',\n",
    "         'answered_correctly':'int8'}\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv'\n",
    "                       ,usecols=[1, 2, 3, 4, 7]\n",
    "                       ,dtype=dtype\n",
    "                       ,nrows = settings['n_train_rows']\n",
    "                      )\n",
    "\n",
    "# Keep only questions\n",
    "train_df = train_df[train_df.content_type_id == False]\n",
    "\n",
    "# Arrange by timestamp\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# Group each user\n",
    "train_group = train_df[['user_id', 'content_id', 'answered_correctly']]\\\n",
    "            .groupby('user_id')\\\n",
    "            .apply(lambda r: {'content_id' : r['content_id'].values\n",
    "                             ,'answered_correctly' : r['answered_correctly'].values\n",
    "                            })\n",
    "\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Make validation set\n",
    "val_idx = np.random.choice(train_group.index, int(.1 * train_group.shape[0]), replace=False)\n",
    "valid_group = train_group[val_idx].copy()\n",
    "train_group.drop(valid_group.index, inplace=True)\n",
    "\n",
    "class riiid_dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, group, settings):\n",
    "        super(riiid_dataset, self).__init__()\n",
    "        self.seq_len = settings['seq_len']\n",
    "        self.group = group\n",
    "        \n",
    "        # Take out people with only 1 interaction\n",
    "        for user_id in self.group.index:\n",
    "            if len(self.group[user_id]['content_id']) < 2:\n",
    "                del self.group[user_id]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.group))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the relevant user row\n",
    "        sample = self.group.iloc[index]\n",
    "        \n",
    "        # Get contents as np.int64s\n",
    "        content_id = sample['content_id'].astype(np.int64)\n",
    "        answered_correctly = sample['answered_correctly'].astype(np.int64)\n",
    "        \n",
    "        # Helper function to pad vector\n",
    "        def pad(np_array, out_size=self.seq_len):\n",
    "            n_pad = out_size - len(np_array)\n",
    "            if n_pad > 0:\n",
    "                np_array = np.concatenate((np.full(n_pad, 0).astype(np.int64), np_array))\n",
    "            else:\n",
    "                np_array = np_array[:out_size]\n",
    "            return(np_array)\n",
    "                \n",
    "        content_id = pad(content_id)\n",
    "        answered_correctly = pad(answered_correctly)\n",
    "        prev_ac = pad(answered_correctly, self.seq_len + 1)\n",
    "        prev_ac = prev_ac[:-1]\n",
    "        \n",
    "        # Return\n",
    "        return({\n",
    "            'content_id' : content_id\n",
    "            ,'answered_correctly' : answered_correctly\n",
    "            ,'prev_ac' : prev_ac\n",
    "        })\n",
    "    \n",
    "\n",
    "train_dataset = riiid_dataset(group = train_group\n",
    "                              ,settings = settings\n",
    "                              )\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset\n",
    "                                                ,batch_size = settings['batch_size']\n",
    "                                                ,drop_last = True\n",
    "                                                ,shuffle = True\n",
    "                                                ,num_workers = 4\n",
    "                                               )\n",
    "\n",
    "valid_dataset = riiid_dataset(group = valid_group\n",
    "                             ,settings = settings\n",
    "                             )\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset\n",
    "                                               ,batch_size = settings['batch_size']\n",
    "                                               ,drop_last = True\n",
    "                                              )\n",
    "\n",
    "\n",
    "class encoder(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(encoder, self).__init__()\n",
    "        self.embed_dim = settings['embed_dim']\n",
    "        self.n_content_id = settings['n_content_id']\n",
    "        self.seq_len = settings['seq_len']\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        self.cid_embedding = torch.nn.Embedding(self.n_content_id, self.embed_dim)\n",
    "        self.pos_embedding = torch.nn.Embedding(self.seq_len, self.embed_dim)\n",
    "        self.multi_att = torch.nn.MultiheadAttention(embed_dim = self.embed_dim\n",
    "                                                     ,num_heads = 8\n",
    "                                                     ,dropout = 0.2)\n",
    "\n",
    "        self.lin_1 = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.lin_2 = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "            \n",
    "    def forward(self, batch):\n",
    "        # Content embedding\n",
    "        x = self.cid_embedding(batch['content_id'])\n",
    "        \n",
    "        # Position embedding\n",
    "        pos_id = torch.arange(x.shape[1])[None, :].to(self.device)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        \n",
    "        # Add embeddings and permute\n",
    "        x = x + pos_x\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        \n",
    "        # MultiHead Attention and permute back\n",
    "        attn_mask = torch.from_numpy(np.triu(np.ones((self.seq_len,self.seq_len)), k=1)\\\n",
    "                                         .astype('bool')).to(self.device) # torch.triu does not have k argument\n",
    "        attn_output, _ = self.multi_att(x, x, x, attn_mask = attn_mask)\n",
    "        x = x + attn_output\n",
    "        \n",
    "        # Feed forward\n",
    "        x = self.lin_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Return\n",
    "        return(x)\n",
    "        \n",
    "class decoder(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(decoder, self).__init__()\n",
    "        self.embed_dim = settings['embed_dim']\n",
    "        self.seq_len = settings['seq_len']\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        self.prev_ac_embedding = torch.nn.Embedding(10, self.embed_dim)\n",
    "        self.pos_embedding = torch.nn.Embedding(self.seq_len, self.embed_dim)\n",
    "        self.multi_att_1 = torch.nn.MultiheadAttention(embed_dim = self.embed_dim\n",
    "                                                     ,num_heads = 8\n",
    "                                                     ,dropout = 0.2)\n",
    "        self.multi_att_2 = torch.nn.MultiheadAttention(embed_dim = self.embed_dim\n",
    "                                                      ,num_heads = 8\n",
    "                                                      ,dropout = 0.2)\n",
    "        \n",
    "        self.lin_1 = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.lin_2 = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(0.2)        \n",
    "        \n",
    "    def forward(self, batch, x):\n",
    "        # Previous answered_correctly embedding\n",
    "        y = self.prev_ac_embedding(batch['prev_ac'])\n",
    "        \n",
    "        # Position embedding\n",
    "        pos_id = torch.arange(y.shape[1])[None, :].to(self.device)\n",
    "        pos_y = self.pos_embedding(pos_id)\n",
    "        \n",
    "        # Add embeddings and permute\n",
    "        y = y + pos_y\n",
    "        y = y.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        \n",
    "        # MultiHead Attention 1\n",
    "        attn_mask = torch.from_numpy(np.triu(np.ones((self.seq_len,self.seq_len)), k=1)\\\n",
    "                                         .astype('bool')).to(self.device) # torch.triu does not have k argument\n",
    "        \n",
    "        attn_output_1, _ = self.multi_att_1(y, y, y, attn_mask = attn_mask)\n",
    "        y = y + attn_output_1\n",
    "        \n",
    "        # MultiHead Attention 2\n",
    "        attn_output_2, _ = self.multi_att_2(y, x, x, attn_mask = attn_mask) # query, key, value\n",
    "        y = y + attn_output_2\n",
    "        \n",
    "        # Permute back to [batch_size, seq_len, embed_dim]\n",
    "        y = y.permute(1, 0, 2)\n",
    "        \n",
    "        # Feed forward\n",
    "        y = self.lin_1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.lin_2(y)\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        # Return\n",
    "        return(y)\n",
    "        \n",
    "class riiid_model(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(riiid_model, self).__init__()\n",
    "        self.embed_dim = settings['embed_dim']\n",
    "        self.seq_len = settings['seq_len']\n",
    "        self.device = settings['seq_len']\n",
    "        self.encoder = encoder(settings=settings)\n",
    "        self.decoder = decoder(settings=settings)\n",
    "        self.emb_to_seq = torch.nn.Linear(self.embed_dim, 1)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x = self.encoder(batch)\n",
    "        y = self.decoder(batch, x)\n",
    "        y = self.emb_to_seq(y)\n",
    "        y = y[:,:,0]\n",
    "        return(y)\n",
    "\n",
    "        \n",
    "# Setup model, optimizer and criterion\n",
    "model = riiid_model(settings)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "all_auc = []\n",
    "\n",
    "# Move model and criteriod to device\n",
    "model.to(settings['device'])\n",
    "criterion.to(settings['device'])\n",
    "\n",
    "# Get content_ids and pad\n",
    "for _ in range(5):\n",
    "    tbar = tqdm.tqdm(train_dataloader)\n",
    "    for batch in tbar:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(settings['device'])\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch['answered_correctly'].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # For now, do AUC on only the last prediction\n",
    "        t = batch['answered_correctly'][:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "        p = pred[:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "        auc = sklearn.metrics.roc_auc_score(t, p)\n",
    "        all_auc.append(auc)\n",
    "        \n",
    "print(np.array(all_auc[-200:]).mean())\n",
    "matplotlib.pyplot.plot(all_auc)\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "# Validation\n",
    "val_ac = np.array([])\n",
    "val_pred = np.array([])\n",
    "\n",
    "for batch in valid_dataloader:\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].to(settings['device'])\n",
    "    #optimizer.zero_grad()\n",
    "    pred = model(batch)\n",
    "    #loss = criterion(pred, batch['answered_correctly'].float())\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    # For now, do AUC on only the last prediction\n",
    "    t = batch['answered_correctly'][:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "    p = pred[:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "    \n",
    "    # Concatenate\n",
    "    val_ac = np.concatenate((val_ac, t))\n",
    "    val_pred = np.concatenate((val_pred, p))\n",
    "        \n",
    "sklearn.metrics.roc_auc_score(val_ac, val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### riiid-model-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/m10515009/saint-is-all-you-need-training-private-0-801\n",
    "\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot\n",
    "\n",
    "import torch\n",
    "\n",
    "settings = {}\n",
    "settings['seq_len'] = 160\n",
    "settings['n_content_id'] = 13525\n",
    "settings['batch_size'] = 100\n",
    "settings['embed_dim'] = 256\n",
    "settings['n_train_rows'] = 5 * 1000000\n",
    "settings['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dtype = {'timestamp':'int64', \n",
    "         'user_id':'int32' ,\n",
    "         'content_id':'int16',\n",
    "         'content_type_id':'int8',\n",
    "         'answered_correctly':'int8'}\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv'\n",
    "                       ,usecols=[1, 2, 3, 4, 7]\n",
    "                       ,dtype=dtype\n",
    "                       ,nrows = settings['n_train_rows']\n",
    "                      )\n",
    "\n",
    "# Keep only questions\n",
    "train_df = train_df[train_df.content_type_id == False]\n",
    "\n",
    "# Arrange by timestamp\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# Group each user\n",
    "train_group = train_df[['user_id', 'content_id', 'answered_correctly']]\\\n",
    "            .groupby('user_id')\\\n",
    "            .apply(lambda r: {'content_id' : r['content_id'].values\n",
    "                             ,'answered_correctly' : r['answered_correctly'].values\n",
    "                            })\n",
    "\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Make validation set\n",
    "val_idx = np.random.choice(train_group.index, int(.1 * train_group.shape[0]), replace=False)\n",
    "valid_group = train_group[val_idx].copy()\n",
    "train_group.drop(valid_group.index, inplace=True)\n",
    "\n",
    "class riiid_dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, group, settings):\n",
    "        super(riiid_dataset, self).__init__()\n",
    "        self.seq_len = settings['seq_len']\n",
    "        self.group = group\n",
    "        \n",
    "        # Take out people with only 1 interaction\n",
    "        for user_id in self.group.index:\n",
    "            if len(self.group[user_id]['content_id']) < 2:\n",
    "                del self.group[user_id]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.group))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the relevant user row\n",
    "        sample = self.group.iloc[index]\n",
    "        \n",
    "        # Get contents as np.int64s\n",
    "        content_id = sample['content_id'].astype(np.int64)\n",
    "        answered_correctly = sample['answered_correctly'].astype(np.int64)\n",
    "        \n",
    "        # Helper function to pad vector\n",
    "        def pad(np_array, out_size=self.seq_len):\n",
    "            n_pad = out_size - len(np_array)\n",
    "            if n_pad > 0:\n",
    "                np_array = np.concatenate((np.full(n_pad, 0).astype(np.int64), np_array))\n",
    "            else:\n",
    "                np_array = np_array[:out_size]\n",
    "            return(np_array)\n",
    "                \n",
    "        content_id = pad(content_id)\n",
    "        answered_correctly = pad(answered_correctly)\n",
    "        prev_ac = pad(answered_correctly, self.seq_len + 1)\n",
    "        prev_ac = prev_ac[:-1]\n",
    "        \n",
    "        # Return\n",
    "        return({\n",
    "            'content_id' : content_id\n",
    "            ,'answered_correctly' : answered_correctly\n",
    "            ,'prev_ac' : prev_ac\n",
    "        })\n",
    "    \n",
    "\n",
    "train_dataset = riiid_dataset(group = train_group\n",
    "                              ,settings = settings\n",
    "                              )\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset\n",
    "                                                ,batch_size = settings['batch_size']\n",
    "                                                ,drop_last = True\n",
    "                                                ,shuffle = True\n",
    "                                                ,num_workers = 4\n",
    "                                               )\n",
    "\n",
    "valid_dataset = riiid_dataset(group = valid_group\n",
    "                             ,settings = settings\n",
    "                             )\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset\n",
    "                                               ,batch_size = settings['batch_size']\n",
    "                                               ,drop_last = True\n",
    "                                              )\n",
    "\n",
    "class riiid_encoder(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(riiid_encoder, self).__init__()\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        self.cid_embedding = torch.nn.Embedding(settings['n_content_id'], settings['embed_dim'])\n",
    "        self.pos_embedding = torch.nn.Embedding(settings['seq_len'], settings['embed_dim'])\n",
    "            \n",
    "    def forward(self, batch):\n",
    "        # Content embedding\n",
    "        x = self.cid_embedding(batch['content_id'])\n",
    "        \n",
    "        # Position embedding\n",
    "        pos_id = torch.arange(x.shape[1])[None, :].to(self.device)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        \n",
    "        # Add embeddings and permute\n",
    "        x = x + pos_x\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "\n",
    "        # Return\n",
    "        return(x)\n",
    "        \n",
    "class riiid_decoder(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(riiid_decoder, self).__init__()\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        self.prev_ac_embedding = torch.nn.Embedding(2, settings['embed_dim'])\n",
    "        self.pos_embedding = torch.nn.Embedding(settings['seq_len'], settings['embed_dim'])\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # Previous answered_correctly embedding\n",
    "        y = self.prev_ac_embedding(batch['prev_ac'])\n",
    "        \n",
    "        # Position embedding\n",
    "        pos_id = torch.arange(y.shape[1])[None, :].to(self.device)\n",
    "        pos_y = self.pos_embedding(pos_id)\n",
    "        \n",
    "        # Add embeddings and permute\n",
    "        y = y + pos_y\n",
    "        y = y.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        \n",
    "        # Return\n",
    "        return(y)\n",
    "        \n",
    "class riiid_model(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        # Initialize\n",
    "        super(riiid_model, self).__init__()\n",
    "        self.seq_len = settings['seq_len']\n",
    "        self.device = settings['device']\n",
    "        \n",
    "        # Encoder and Decoder\n",
    "        self.encoder = riiid_encoder(settings)\n",
    "        self.decoder = riiid_decoder(settings)\n",
    "        \n",
    "        # Transformer\n",
    "        self.transformer = torch.nn.Transformer(nhead = 8\n",
    "                                                ,d_model = settings['embed_dim']\n",
    "                                                ,num_encoder_layers = 2\n",
    "                                                ,num_decoder_layers = 2\n",
    "                                                ,dropout = .2\n",
    "                                               )\n",
    "        \n",
    "        # FFN\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(settings['embed_dim']) \n",
    "        self.lin_1 = torch.nn.Linear(settings['embed_dim'], settings['embed_dim'])\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.lin_2 = torch.nn.Linear(settings['embed_dim'], settings['embed_dim'])\n",
    "        self.dropout = torch.nn.Dropout(.2)        \n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(settings['embed_dim'])\n",
    "        \n",
    "        # Prediction\n",
    "        self.pred = torch.nn.Linear(settings['embed_dim'], 1)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # Get encodings/decodings\n",
    "        x = self.encoder(batch)\n",
    "        y = self.decoder(batch)\n",
    "        \n",
    "        # Put them through transformer\n",
    "        mask = torch.from_numpy(np.triu(np.ones((self.seq_len,self.seq_len)), k=1)\\\n",
    "                         .astype('bool')).to(self.device) # torch.triu does not have k argument\n",
    "        t = self.transformer(src = x\n",
    "                             ,tgt = y\n",
    "                             ,src_mask = mask\n",
    "                             ,tgt_mask = mask\n",
    "                             ,memory_mask = mask\n",
    "                            )\n",
    "        t = self.layer_norm_1(t)\n",
    "        t = t.permute(1, 0, 2)\n",
    "        \n",
    "        # FFN        \n",
    "        z = self.lin_1(t)\n",
    "        z = self.relu(z)\n",
    "        z = self.lin_2(z)\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        # LayerNorm with z + t\n",
    "        z = self.layer_norm_2(z + t)\n",
    "        \n",
    "        \n",
    "        # Permute and predict\n",
    "        z = self.pred(z)\n",
    "        z = z[:,:,0]\n",
    "        return(z)\n",
    "\n",
    "        \n",
    "# Setup model, optimizer and criterion\n",
    "model = riiid_model(settings)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "all_auc = []\n",
    "\n",
    "# Move model and criteriod to device\n",
    "model.to(settings['device'])\n",
    "criterion.to(settings['device'])\n",
    "\n",
    "\n",
    "# Get content_ids and pad\n",
    "for _ in range(10):\n",
    "    tbar = tqdm.tqdm(train_dataloader)\n",
    "    for batch in tbar:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(settings['device'])\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch['answered_correctly'].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # For now, do AUC on only the last prediction\n",
    "        t = batch['answered_correctly'][:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "        p = pred[:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "        auc = sklearn.metrics.roc_auc_score(t, p)\n",
    "        all_auc.append(auc)\n",
    "        \n",
    "        \n",
    "print(np.array(all_auc[-200:]).mean())\n",
    "matplotlib.pyplot.plot(all_auc)\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "\n",
    "# Validation\n",
    "val_ac = np.array([])\n",
    "val_pred = np.array([])\n",
    "\n",
    "for batch in valid_dataloader:\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].to(settings['device'])\n",
    "        \n",
    "    # Get predictions\n",
    "    pred = model(batch)\n",
    "    \n",
    "    # For now, do AUC on only the last prediction\n",
    "    t = batch['answered_correctly'][:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "    p = pred[:, -1:][:, -1].detach().to('cpu').numpy()\n",
    "    \n",
    "    # Concatenate\n",
    "    val_ac = np.concatenate((val_ac, t))\n",
    "    val_pred = np.concatenate((val_pred, p))\n",
    "        \n",
    "sklearn.metrics.roc_auc_score(val_ac, val_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
